{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@triton.jit\n",
    "def layernorm_kernel_fwd(x_ptr, output_ptr, w_ptr, b_ptr, stride, n_cols, eps, BLOCK_SIZE: tl.constexpr):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    offsets = tl.arange(0, BLOCK_SIZE)\n",
    "    x_ptrs = x_ptr + pid * stride + offsets\n",
    "    mask = offsets < n_cols\n",
    "    x = tl.load(x_ptrs, mask=mask, other=0.)\n",
    "    mean = tl.sum(x) / n_cols\n",
    "    x_minus_mean = tl.where(offsets < n_cols, x - mean, 0.)\n",
    "    var = tl.sum(x_minus_mean * x_minus_mean) / n_cols\n",
    "    rstd = 1 / tl.sqrt(var + eps)\n",
    "    x_hat = (x - mean) * rstd\n",
    "    \n",
    "    w = tl.load(w_ptr + offsets, mask=mask, other=0.)\n",
    "    b = tl.load(b_ptr + offsets, mask=mask, other=0.)\n",
    "    output = x_hat * w + b\n",
    "    tl.store(output_ptr + pid * stride + offsets, output, mask=mask)"
   ],
   "id": "434a12b2c3e60601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def layer_norm(x, normalized_shape, weight, bias, eps):\n",
    "    M, N = x.shape\n",
    "    y = torch.empty_like(x)\n",
    "    \n",
    "    BLOCK_SIZE = triton.next_power_of_2(N)\n",
    "    num_warps = min(max(BLOCK_SIZE // 256, 1), 8)\n",
    "\n",
    "    layernorm_kernel_fwd[(M,)](x, y, weight, bias, x.stride(0), N, eps, BLOCK_SIZE=BLOCK_SIZE, num_warps=num_warps)\n",
    "    return y"
   ],
   "id": "e62482ada3faff69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_layer_norm(M, N, dtype, eps=1e-5, device='cuda'):\n",
    "    x_shape = (M, N)\n",
    "    w_shape = (x_shape[-1], )\n",
    "    weight = torch.rand(w_shape, dtype=dtype, device=device)\n",
    "    bias = torch.rand(w_shape, dtype=dtype, device=device)\n",
    "    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device=device)\n",
    "    y_tri = layer_norm(x, w_shape, weight, bias, eps)\n",
    "    y_ref = torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps).to(dtype)\n",
    "    # print(y_tri)\n",
    "    # print(y_ref)\n",
    "    assert torch.allclose(y_tri, y_ref, atol=1e-2, rtol=0)"
   ],
   "id": "1d72c236858d86ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['N'],  # argument names to use as an x-axis for the plot\n",
    "        x_vals=[512 * i for i in range(2, 64)],  # different possible values for `x_name`\n",
    "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
    "        line_vals=['triton', 'torch'],  # possible values for `line_arg``\n",
    "        line_names=[\n",
    "            \"Triton\",\n",
    "            \"Torch\",\n",
    "        ],  # label name for the lines\n",
    "        styles=[('blue', '-'), ('green', '-')],  # line styles\n",
    "        ylabel=\"GB/s\",  # label name for the y-axis\n",
    "        plot_name=\"layernorm-performance\",  # name for the plot. Used also as a file name for saving the plot.\n",
    "        args={'M': 4096, 'dtype': torch.float32, 'mode': 'forward'},  # values for function arguments not in `x_names` and `y_name`\n",
    "    ))\n",
    "def benchmark(M, N, dtype, provider, mode='forward', eps=1e-5, device='cuda'):\n",
    "    # create data\n",
    "    x_shape = (M, N)\n",
    "    w_shape = (x_shape[-1], )\n",
    "    weight = torch.rand(w_shape, dtype=dtype, device=device)\n",
    "    bias = torch.rand(w_shape, dtype=dtype, device=device)\n",
    "    x = -2.3 + 0.5 * torch.randn(x_shape, dtype=dtype, device=device)\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "\n",
    "    def y_fwd():\n",
    "        if provider == 'torch':\n",
    "            return layer_norm(x, w_shape, weight, bias, eps)\n",
    "        if provider == 'triton':\n",
    "            return torch.nn.functional.layer_norm(x, w_shape, weight, bias, eps)  \n",
    "    \n",
    "    if mode == 'forward':\n",
    "        gbps = lambda ms: 2 * x.numel() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(y_fwd, quantiles=quantiles, rep=500)\n",
    "    \n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "test_layer_norm(1151, 20000, torch.float32)\n",
    "benchmark.run(show_plots=True, print_data=True)"
   ],
   "id": "ee089ec0fb8c9e68",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
